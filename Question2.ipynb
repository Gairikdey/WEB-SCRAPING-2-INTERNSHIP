{"metadata":{"orig_nbformat":4,"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport pandas as pd\nimport undetected_chromedriver as uc\nfrom selenium import webdriver \nfrom selenium.webdriver.common.by import By\n# job-title, job-location, company_name,\n# experience_required.\n\n# enter keyword to search (URL)\nkeyword = \"https://www.naukri.com/\"\ndriver.get(keyword)\n\ntime.sleep(2)\n# closing the 3 popup windows\nfor _ in range(3):\n    driver.switch_to.window(driver.window_handles[-1])\n    time.sleep(1)\n    driver.close()\ndriver.switch_to.window(driver.window_handles[-1])\n\ntime.sleep(1)\n# job skill\nJob_skill_position = \"Data Scientist\"\nskill_box = driver.find_element(By.XPATH,\"//input[@placeholder='Skills, Designations, Companies']\")\nskill_box.send_keys(Job_skill_position)\n\n# location\nlocation = \"Bangalore\"\nlocation_box = driver.find_element(By.XPATH,\"//input[@placeholder='Enter Locationsâ€¦']\")\nlocation_box.send_keys(location)\n\ntime.sleep(1)\n\n# search button\ndriver.find_element(By.XPATH, \"//button[text()='Search']\").click()\ntime.sleep(4)\n# creating empty lists for scraping data\njob_title=[]\njob_location=[]\ncompany_name=[]\nfull_job_description=[]\n# job postings\narticles = driver.find_elements(By.XPATH,\"//article[@class='jobTuple bgWhite br4 mb-8']\")[:10]\ntitles = []\nurls = []\njob_descriptions = []\ncompanies = []\nlocations = []\ncolumns = [\"Job Title\",' Company','Location', \"Job Description\"]\n\n# parse data\nfor article in articles:\n    \n    # job title\n    title = article.find_element(By.XPATH,\".//a[@class='title fw500 ellipsis']\").text.strip()\n    \n    # company names\n    company = article.find_element(By.XPATH,\".//a[@class='subTitle ellipsis fleft']\").text.strip()\n    \n    # for description\n    url = article.find_element(By.XPATH,\".//a[@class='title fw500 ellipsis']\").get_attribute('href')\n    urls.append(url)\n    \n    # location\n    location = article.find_element(By.XPATH,\".//li[@class='fleft grey-text br2 placeHolderLi location']\") \\\n                      .text.strip()\n    \n    titles.append(title)\n    companies.append(company)\n    locations.append(location)\n#     print(\"Title: \",title, \"Company: \", company)\n#     print(\"Location: \", location)\n#     print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n# get job descriptions\nfor url in urls:\n    try:\n        driver.get(url)\n        raw_description=driver.find_element(By.XPATH,\"//section[@class='job-desc']/div[1]\").text\n        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n        description= description.split(\"@@@@@\")\n        job_description.append(description[0])\n    except NoSuchElementException :\n        job_description.append(\"---\")\ndata_dict = {\n    columns[0] : titles,\n    columns[1] : companies,\n    columns[2] : locations,\n    columns[3] : job_descriptions\n}\n# creating the dataframe from the scraped data and taking only first 10 jobs\ndf=pd.DataFrame(data_dict)\ndf.tail(10)\ndriver.quit()","metadata":{},"execution_count":null,"outputs":[],"id":"090df4f8-c83f-4c17-a447-cd97baf91bfa"}]}